{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d80afa-5550-4b79-b73f-8b803118613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "current_path = Path().resolve().parent\n",
    "print(current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca7384c-62fe-49f9-a053-87f4fcaa132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pt_file(folder_path):\n",
    "    # List all files in the folder\n",
    "    all_files = os.listdir(folder_path)\n",
    "    \n",
    "    # Filter out the .pt files\n",
    "    pt_filename = [f for f in all_files if f.endswith('.pt')][0]\n",
    "\n",
    "    return int(pt_filename.split(\".\")[0].split('_')[-1])\n",
    "\n",
    "def get_best_model_f1(folder_path):\n",
    "\n",
    "    best_f1 = 0\n",
    "    best_iter = 0\n",
    "    \n",
    "    for i in range(10):\n",
    "        df = pd.read_csv(folder_path / f'test_results_exp_{i}.csv')\n",
    "        true_labels = df['true_label']\n",
    "        predictions = df['prediction']\n",
    "\n",
    "        score = f1_score(true_labels, predictions, average='macro')\n",
    "        if score > best_f1:\n",
    "            best_f1 = score\n",
    "            best_iter = i\n",
    "\n",
    "    return best_iter, best_f1\n",
    "\n",
    "\n",
    "def get_labels_and_predictions(corpus, model, task):\n",
    "\n",
    "    results_path = current_path / 'results' / f\"{corpus}-{model}-{task}/\"\n",
    "    \n",
    "    best_iter, best_f1 = get_best_model_f1(results_path) # based on f1-score on testing set\n",
    "\n",
    "    print(corpus, model, task, round(best_f1, 3))\n",
    "\n",
    "    df = pd.read_csv(results_path / f'test_results_exp_{best_iter}.csv')\n",
    "    true_labels = df['true_label']\n",
    "    predictions = df['prediction']\n",
    "\n",
    "    return true_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d1fe67-cde7-4eaf-a553-2bc3ebf4d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1, predictions1 = get_labels_and_predictions('ibm', 'bert', 'multi')\n",
    "labels2, predictions2 = get_labels_and_predictions('ukp', 'bert', 'multi')\n",
    "\n",
    "# Function to plot a confusion matrix\n",
    "def plot_confusion_matrix(ax, labels_true, labels_pred, title, prec_or_rec):\n",
    "    cm = confusion_matrix(labels_true, labels_pred)\n",
    "\n",
    "    names_list = ['Correct', 'Flipped', 'Neutralized', 'Polarized']\n",
    "\n",
    "    cm_to_plot = cm\n",
    "    formato = \"d\"\n",
    "    if prec_or_rec == 'recall':\n",
    "        cm_to_plot = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100 # cm_row_norm\n",
    "        formato = \".0f\"\n",
    "    elif prec_or_rec == 'precision':\n",
    "        cm_to_plot = cm.astype('float') / cm.sum(axis=0)[np.newaxis, :] * 100 # cm_col_norm\n",
    "        formato = \".0f\"\n",
    "\n",
    "    sns.heatmap(cm_to_plot, annot=True, fmt=formato, cmap=\"Blues\", ax=ax, cbar = False, annot_kws={\"size\": 14})\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Predicho')\n",
    "    ax.set_xticklabels(names_list)\n",
    "    ax.set_yticklabels(names_list)\n",
    "    ax.set_ylabel('Correcto')\n",
    "\n",
    "# Create subplots for three confusion matrices in a row\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot each confusion matrix\n",
    "metrc = 'recmfefeall'\n",
    "plot_confusion_matrix(ax1, labels1, predictions1, r'$EVI^{\\dagger}$', metrc)\n",
    "plot_confusion_matrix(ax2, labels2, predictions2, r'$UKP^{\\dagger}$', metrc)\n",
    "\n",
    "# # Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(str((current_path) / 'figures' / 'ch8-confusionMatrices.pdf'), format='pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
