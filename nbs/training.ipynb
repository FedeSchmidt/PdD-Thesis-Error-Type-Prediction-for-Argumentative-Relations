{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-27T22:44:42.455092Z",
     "iopub.status.busy": "2024-10-27T22:44:42.454169Z",
     "iopub.status.idle": "2024-10-27T22:44:49.937576Z",
     "shell.execute_reply": "2024-10-27T22:44:49.935942Z",
     "shell.execute_reply.started": "2024-10-27T22:44:42.455056Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import torch\n",
    "import ast\n",
    "from torch import nn\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import copy\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from transformers import AutoTokenizer, DistilBertModel, BertModel, AutoModel\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW, Adam\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "print(device)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "\n",
    "def generate_random_seed():\n",
    "    return random.randint(1, 1000)\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T22:44:49.940270Z",
     "iopub.status.busy": "2024-10-27T22:44:49.939725Z",
     "iopub.status.idle": "2024-10-27T22:44:49.985247Z",
     "shell.execute_reply": "2024-10-27T22:44:49.984093Z",
     "shell.execute_reply.started": "2024-10-27T22:44:49.940237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# save model to disc\n",
    "def save_model_state(model_state, PATH):\n",
    "    torch.save(model_state, PATH)\n",
    "    \n",
    "# load and returns a previously saved model\n",
    "def load_model(PATH, model_checkpoint):\n",
    "    model = CustomClassifier(NUM_CLASSES, model_checkpoint)\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    return model\n",
    "    \n",
    "def transform_label(x, name_classes):\n",
    "    return name_classes.index(x)\n",
    "\n",
    "def save_training_information(info, exp):\n",
    "    cols = info[0]\n",
    "    pd.DataFrame(info[1:], columns = cols).to_csv(f'results_train_{exp}.csv', index = False)\n",
    "\n",
    "# dataset class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, predictions, labels):\n",
    "        self.encodings = encodings\n",
    "        self.predictions = predictions\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['predictions'] = torch.tensor(self.predictions[idx])\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "class CustomClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, model_checkpoint):\n",
    "        print(model_checkpoint)\n",
    "        super(CustomClassifier, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.transformer = AutoModel.from_pretrained(model_checkpoint)\n",
    "        self.classifier = nn.Linear(768 * 3, self.num_labels) \n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, stance_predictions):\n",
    "        if token_type_ids is not None:\n",
    "            x = self.transformer(input_ids, \n",
    "                            token_type_ids = token_type_ids, \n",
    "                            attention_mask = attention_mask,\n",
    "                            output_hidden_states = False)\n",
    "            x = x.pooler_output\n",
    "        else:\n",
    "            x = self.transformer(input_ids, \n",
    "                            attention_mask = attention_mask,\n",
    "                            output_hidden_states = False)\n",
    "            x = x.last_hidden_state\n",
    "            x = x.mean(dim = 1)\n",
    "            \n",
    "        x_expanded = x.unsqueeze(1).repeat(1, 3, 1) \n",
    "        x_expanded = x_expanded.view(x.size(0), -1)\n",
    "        stance_expanded = stance_predictions.repeat_interleave(768, dim=1)\n",
    "        x = x_expanded * stance_expanded\n",
    "                \n",
    "        hidden = self.dropout(nn.LeakyReLU()(x))\n",
    "         \n",
    "        output = self.classifier(hidden)\n",
    "        return output\n",
    "    \n",
    "def prepare_input_with_topic(df, labels, tokenizer, max_len = 128, shuffle = True, bs = 32):\n",
    "        \n",
    "    arguments = df['Sentence1'].values\n",
    "    topics  = df['Sentence2'].values\n",
    "    \n",
    "    predictions = pd.get_dummies(df['predicted'])\n",
    "    predictions = predictions.astype(int).values.tolist()\n",
    "\n",
    "    arguments = [str(arg) for arg in arguments]\n",
    "    topics = [str(tp) for tp in topics]\n",
    "    \n",
    "    encodings = tokenizer(list(arguments), list(topics), \n",
    "                          truncation=True, \n",
    "                          padding='max_length', \n",
    "                          max_length=max_len)\n",
    "    \n",
    "    dst = CustomDataset(encodings, predictions, labels)\n",
    "    dataloader = DataLoader(dst, batch_size = bs, shuffle = shuffle)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def divide_dataset(df, rs):\n",
    "    filtered_df = df.copy()\n",
    "    filtered_df = filtered_df[['Set', 'Sentence1', 'Sentence2', 'predicted', 'error_type']]\n",
    "    \n",
    "    X_train = filtered_df[filtered_df['Set'] == 'train']\n",
    "    X_test = filtered_df[filtered_df['Set'] == 'test']\n",
    "    X_dev = filtered_df[filtered_df['Set'] == 'dev']\n",
    "    \n",
    "    return X_train, X_dev, X_test\n",
    "\n",
    "def get_batch_predictions(model, batch, model_name = 'bert', loss_fn = None):\n",
    "    # mini-batch predictions\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    input_type_ids = batch['token_type_ids'].to(device) if model_name == 'bert' else None\n",
    "    \n",
    "    stance_predictions = batch['predictions'].to(device)\n",
    "    labels = batch['labels'].type(torch.LongTensor).to(device)  # BS x1\n",
    "            \n",
    "    # get predictions for the mini-batch\n",
    "    outputs = model(input_ids, attention_mask, input_type_ids, stance_predictions)\n",
    "            \n",
    "    # calculate mini-batch loss and accuracy\n",
    "    loss = None\n",
    "    if loss_fn is not None:\n",
    "        loss = loss_fn(outputs, labels)\n",
    "    \n",
    "    return outputs, labels, loss\n",
    "\n",
    "def finetune_model(model, train_loader, validation_loader, loss_fn, optim, epochs, n_samples, n_eval_samples, model_checkpoint):\n",
    "    best_model_state = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "    output_info = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        \n",
    "        print(\"Epoch: {}/{}\".format(epoch, epochs))\n",
    "        start_time = time.time()\n",
    "        epoch_info = [epoch]\n",
    "        \n",
    "        ## TRAINING LOOP\n",
    "        start_time = time.time()\n",
    "        train_loss, train_hits = 0, 0\n",
    "        model.train()\n",
    "        \n",
    "        for i, batch in enumerate(train_loader, 0):\n",
    "            optim.zero_grad()\n",
    "            \n",
    "            outputs, labels, loss = get_batch_predictions(model, batch, model_checkpoint.split('-')[0], loss_fn)\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_hits += (torch.argmax(outputs, dim = 1) == labels).sum().item()\n",
    "            \n",
    "            # Optimization step\n",
    "            loss.backward()\n",
    "            \n",
    "            # gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            # update learning rates using scheduler\n",
    "            optim.step()\n",
    "                      \n",
    "        # calculate average loss and accuracy\n",
    "        avg_train_loss = round(float(train_loss / n_samples), 4)\n",
    "        train_acc = round(float(train_hits / n_samples), 3)\n",
    "            \n",
    "        ## VALIDATION LOOP\n",
    "        model.eval()\n",
    "        eval_loss = 0\n",
    "        eval_predictions, eval_labels = np.array([], int), np.array([], int)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in validation_loader:\n",
    "                outputs, labels, loss = get_batch_predictions(model, batch, model_checkpoint.split('-')[0], loss_fn)\n",
    "                eval_loss += loss.item()\n",
    "                \n",
    "                eval_predictions = np.concatenate((eval_predictions, torch.argmax(outputs, dim = 1).int().cpu().numpy()), axis = 0)\n",
    "                eval_labels = np.concatenate((eval_labels, labels.int().cpu().numpy()), axis = 0)\n",
    "                \n",
    "        # calculate average loss, accuracy and macro f1 score\n",
    "        avg_eval_loss = round(float(eval_loss / n_eval_samples), 4)\n",
    "        eval_acc = accuracy_score(eval_labels, eval_predictions)\n",
    "        eval_macro_f1 = f1_score(eval_labels, eval_predictions, average = 'macro')\n",
    "        \n",
    "        ## PRINT INFO\n",
    "        print(f\"Training   ==> Accuracy: {train_acc} | Loss: {avg_train_loss}\")\n",
    "        print(f\"Validation ==> Accuracy: {eval_acc}  | Loss: {avg_eval_loss}  | Macro-F1: {eval_macro_f1}\")\n",
    "        \n",
    "        ## SAVE BEST MODEL\n",
    "        ## Save model state when validation loss decreases\n",
    "        if avg_eval_loss < best_loss:\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            best_loss = avg_eval_loss\n",
    "            print(\"Validation loss has decreased... saving model at epoch {}\".format(epoch))\n",
    "            \n",
    "        epoch_info += [avg_train_loss, train_acc, avg_eval_loss, eval_acc, eval_macro_f1, n_samples, n_eval_samples]\n",
    "        output_info.append(epoch_info)\n",
    "    \n",
    "    output_info.insert(0, ['epoch', 'avg_train_loss', 'train_acc', 'avg_eval_loss', 'eval_acc', 'eval_macro_f1', 'train_samples', 'eval_samples'])\n",
    "    return best_model_state, best_loss, output_info\n",
    "\n",
    "def test_model(path, dataloader, model_checkpoint, classes = None):\n",
    "    model = load_model(path, model_checkpoint).to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    predictions, test_labels = np.array([], int), np.array([], int)\n",
    "    logits = np.zeros((0, NUM_CLASSES), dtype=np.float32)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            outputs, labels, loss = get_batch_predictions(model, batch, model_checkpoint.split('-')[0])\n",
    "            \n",
    "            logits = np.concatenate((logits, outputs.cpu().numpy()), axis = 0)\n",
    "            predictions = np.concatenate((predictions, torch.argmax(outputs, dim = 1).int().cpu().numpy()), axis = 0)\n",
    "            test_labels = np.concatenate((test_labels, labels.int().cpu().numpy()), axis = 0)\n",
    "    \n",
    "    return predictions, logits\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 128\n",
    "task = 'binary'\n",
    "\n",
    "df_name = 'generated_ibm_sample1'\n",
    "df = pd.read_csv(f\"/kaggle/input/error-type-predictions-in-argumentative-relations/{df_name}.csv\")\n",
    "\n",
    "names_classes = ['correct', 'flipped', 'neutralized', 'polarized'] if task == 'multi' else ['no-correct', 'correct']\n",
    "NUM_CLASSES = len(names_classes)\n",
    "print(names_classes, NUM_CLASSES)\n",
    "\n",
    "model_checkpoint = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "epochs = 10\n",
    "experiments = 10 # number of models that will be trained and tested.\n",
    "\n",
    "seeds_df = pd.DataFrame(columns=['r_seed', 'indices', 'test_size'])\n",
    "\n",
    "best_model_exp = 0\n",
    "best_model_eval_loss = float('inf')\n",
    "\n",
    "for exp in range(experiments):\n",
    "    \n",
    "    print(f\"Running experiment number {exp}\")\n",
    "    \n",
    "    # setup new model, optimizer, loss function and scheduler before training\n",
    "    # different random seeds are used in each experiment\n",
    "    r_seed = generate_random_seed()\n",
    "    set_random_seed(r_seed)\n",
    "    \n",
    "    # MODEL\n",
    "    model = CustomClassifier(NUM_CLASSES, model_checkpoint)\n",
    "    model.to(device)\n",
    "    \n",
    "    # LOSS FUNCTION\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    ### Optimizer\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr = 1e-5, eps = 1e-8)\n",
    "    \n",
    "    # TRAINING DATA\n",
    "    X_train, X_dev, X_test = divide_dataset(df, r_seed)\n",
    "        \n",
    "    current_df = pd.DataFrame({'r_seed': [r_seed], 'indices': [X_test.index.values.tolist()], 'test_size': len(X_test)})\n",
    "    seeds_df = pd.concat([seeds_df, current_df], ignore_index=True)\n",
    "    \n",
    "    y_train, y_dev, y_test = X_train.pop(\"error_type\").values, X_dev.pop(\"error_type\").values, X_test.pop(\"error_type\").values\n",
    "    train_samples, eval_samples, test_samples = len(y_train), len(y_dev), len(y_test)\n",
    "    print(train_samples, eval_samples, test_samples)\n",
    "    \n",
    "    if task == 'multi':\n",
    "        y_train = [transform_label(x, names_classes) for x in y_train]\n",
    "        y_dev = [transform_label(x, names_classes) for x in y_dev]\n",
    "        y_test = [transform_label(x, names_classes) for x in y_test]\n",
    "    elif task == 'binary':\n",
    "        y_train = [1 if x == 'correct' else 0 for x in y_train]\n",
    "        y_dev = [1 if x == 'correct' else 0 for x in y_dev]\n",
    "        y_test = [1 if x == 'correct' else 0 for x in y_test]\n",
    "    \n",
    "    train_loader = prepare_input_with_topic(X_train, y_train, tokenizer, bs = 32, shuffle = True) \n",
    "    validation_loader = prepare_input_with_topic(X_dev, y_dev, tokenizer, bs = 32, shuffle = True)\n",
    "    test_loader = prepare_input_with_topic(X_test, y_test, tokenizer, bs = 32, shuffle = False)\n",
    "    \n",
    "    best_model, eval_error, train_info = finetune_model(model, train_loader, validation_loader, \n",
    "                                loss_fn, optim, epochs, train_samples, eval_samples, model_checkpoint)\n",
    "        \n",
    "    best_model_name = f\"trained_model_exp_{exp}.pt\"\n",
    "    save_model_state(best_model, best_model_name)\n",
    "    save_training_information(train_info, exp)\n",
    "    \n",
    "    test_predictions, test_logits = test_model(best_model_name, test_loader, model_checkpoint, classes = names_classes)\n",
    "    predictions_df = pd.DataFrame()\n",
    "    predictions_df['true_label'] = y_test\n",
    "    predictions_df['prediction'] = test_predictions\n",
    "    predictions_df['logits_prediction'] = test_logits.tolist()\n",
    "    predictions_df.to_csv(f\"test_results_exp_{exp}.csv\", index = False)\n",
    "    \n",
    "    if eval_error < best_model_eval_loss:\n",
    "        best_model_eval_loss = eval_error\n",
    "        best_model_exp = exp    \n",
    "\n",
    "    print(f\"End of experiment number {exp}\")\n",
    "    print()\n",
    "    \n",
    "seeds_df.to_csv(f\"seeds_{exp}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T19:29:54.826121Z",
     "iopub.status.busy": "2024-10-21T19:29:54.825838Z",
     "iopub.status.idle": "2024-10-21T19:30:19.340389Z",
     "shell.execute_reply": "2024-10-21T19:30:19.339471Z",
     "shell.execute_reply.started": "2024-10-21T19:29:54.826097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from IPython.display import FileLink\n",
    "\n",
    "model_to_save_name = f'trained_model_exp_{best_model_exp}'\n",
    "print(model_to_save_name)\n",
    "\n",
    "def zip_files(folder_path, zip_name):\n",
    "    # Crear un archivo ZIP\n",
    "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # Recorrer todos los archivos en la carpeta\n",
    "        for foldername, subfolders, filenames in os.walk(folder_path):\n",
    "            \n",
    "            for filename in filenames:\n",
    "                if ((filename.endswith(('.txt', '.csv'))) and (not filename.startswith(\"sampling\"))) or filename == f\"{model_to_save_name}.pt\":\n",
    "                    # Ruta completa del archivo\n",
    "                    file_path = os.path.join(foldername, filename)\n",
    "                    # Agregar el archivo al archivo ZIP\n",
    "                    zipf.write(file_path, os.path.relpath(file_path, folder_path))\n",
    "\n",
    "folder_path = '/kaggle/working/'\n",
    "zip_name = 'test.zip'\n",
    "zip_files(folder_path, zip_name)\n",
    "\n",
    "FileLink(r'test.zip')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5355887,
     "sourceId": 9568824,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
